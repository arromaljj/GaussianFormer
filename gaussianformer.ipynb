{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fSKxZP5Wnssj",
        "outputId": "983867e1-6965-4d8b-ac36-ecb7c9918f42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'11.8'"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__\n",
        "torch.version.cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "80T3V80_n9NI"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import argparse\n",
        "import os\n",
        "import os.path as osp\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.distributed as dist\n",
        "\n",
        "from mmengine import Config\n",
        "from mmengine.runner import set_random_seed\n",
        "from mmengine.logging import MMLogger\n",
        "from mmseg.models import build_segmentor\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N1__7sjb1ts",
        "outputId": "9c290609-ac0f-428a-cb43-43845a104d0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-17 06:36:18--  https://cloud.tsinghua.edu.cn/f/d1766fff8ad74756920b/?dl=1\n",
            "Resolving cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)... 101.6.15.69, 2402:f000:1:402:101:6:15:69\n",
            "Connecting to cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)|101.6.15.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cloud.tsinghua.edu.cn/seafhttp/files/02c8dcda-e45c-41b4-9aec-5a6b4ca733a4/state_dict.pth [following]\n",
            "--2025-03-17 06:36:19--  https://cloud.tsinghua.edu.cn/seafhttp/files/02c8dcda-e45c-41b4-9aec-5a6b4ca733a4/state_dict.pth\n",
            "Reusing existing connection to cloud.tsinghua.edu.cn:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 229088996 (218M) [application/octet-stream]\n",
            "Saving to: ‘nonempty.pth’\n",
            "\n",
            "nonempty.pth         12%[=>                  ]  27.29M  5.33MB/s    eta 40s    ^C\n"
          ]
        }
      ],
      "source": [
        "!wget https://cloud.tsinghua.edu.cn/f/d1766fff8ad74756920b/?dl=1 -O nonempty.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "bjUQh3xRpm1q"
      },
      "outputs": [],
      "source": [
        "\n",
        "class EnvironmentManager:\n",
        "    \"\"\"Handles environment setup, configuration, distributed processing, and logging.\"\"\"\n",
        "\n",
        "    def __init__(self, local_rank, args):\n",
        "        \"\"\"\n",
        "        Initialize environment settings and logging.\n",
        "\n",
        "        Args:\n",
        "            local_rank (int): Local rank for distributed processing\n",
        "            args (argparse.Namespace): Command line arguments\n",
        "        \"\"\"\n",
        "        self.local_rank = local_rank\n",
        "        self.args = args\n",
        "        self.distributed = False\n",
        "        self.cfg = None\n",
        "        self.logger = None\n",
        "\n",
        "        # Setup environment in sequence\n",
        "        self._setup_environment()\n",
        "        self._load_config()\n",
        "        self._setup_distributed()\n",
        "        self._setup_logging()\n",
        "\n",
        "    def _setup_environment(self):\n",
        "        \"\"\"Set up environment variables and random seeds for reproducibility.\"\"\"\n",
        "        set_random_seed(self.args.seed)\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    def _load_config(self):\n",
        "        \"\"\"Load configuration from file.\"\"\"\n",
        "        self.cfg = Config.fromfile(self.args.py_config)\n",
        "        self.cfg.work_dir = self.args.work_dir\n",
        "\n",
        "        # Ensure work directory exists\n",
        "        os.makedirs(self.args.work_dir, exist_ok=True)\n",
        "\n",
        "    def _setup_distributed(self):\n",
        "        \"\"\"Set up distributed data parallel processing if multiple GPUs are available.\"\"\"\n",
        "        if self.args.gpus > 1:\n",
        "            self.distributed = True\n",
        "\n",
        "            # Get environment variables for distributed setup\n",
        "            ip = os.environ.get(\"MASTER_ADDR\", \"127.0.0.1\")\n",
        "            port = os.environ.get(\"MASTER_PORT\", \"20507\")\n",
        "            hosts = int(os.environ.get(\"WORLD_SIZE\", 1))  # number of nodes\n",
        "            rank = int(os.environ.get(\"RANK\", 0))  # node id\n",
        "            gpus = torch.cuda.device_count()  # gpus per node\n",
        "\n",
        "            if self.local_rank == 0:\n",
        "                print(f\"Initializing DDP: tcp://{ip}:{port}\")\n",
        "\n",
        "            # Initialize process group\n",
        "            dist.init_process_group(\n",
        "                backend=\"nccl\",\n",
        "                init_method=f\"tcp://{ip}:{port}\",\n",
        "                world_size=hosts * gpus,\n",
        "                rank=rank * gpus + self.local_rank\n",
        "            )\n",
        "\n",
        "            world_size = dist.get_world_size()\n",
        "            self.cfg.gpu_ids = range(world_size)\n",
        "            torch.cuda.set_device(self.local_rank)\n",
        "\n",
        "            # Suppress prints on non-master processes\n",
        "            if self.local_rank != 0:\n",
        "                import builtins\n",
        "                builtins.print = self.pass_print\n",
        "        else:\n",
        "            self.distributed = False\n",
        "\n",
        "    def _setup_logging(self):\n",
        "        \"\"\"Set up logging with timestamp.\"\"\"\n",
        "        timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
        "        log_file = osp.join(self.args.work_dir, f'{timestamp}.log')\n",
        "        self.logger = MMLogger('selfocc', log_file=log_file)\n",
        "        MMLogger._instance_dict['selfocc'] = self.logger\n",
        "\n",
        "        if self.local_rank == 0:\n",
        "            self.logger.info(f\"Configuration:\\n{self.cfg.pretty_text}\")\n",
        "\n",
        "    def pass_print(self, *args, **kwargs):\n",
        "        \"\"\"Empty print function for non-master processes.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def is_master(self):\n",
        "        \"\"\"Check if this process is the master process.\"\"\"\n",
        "        return self.local_rank == 0\n",
        "\n",
        "    def get_logger(self):\n",
        "        \"\"\"Get the logger instance.\"\"\"\n",
        "        return self.logger\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"Get the configuration instance.\"\"\"\n",
        "        return self.cfg\n",
        "\n",
        "\n",
        "class ModelManager:\n",
        "    \"\"\"Handles model creation, initialization, and checkpoint loading.\"\"\"\n",
        "\n",
        "    def __init__(self, env_manager):\n",
        "        \"\"\"\n",
        "        Initialize the model manager.\n",
        "\n",
        "        Args:\n",
        "            env_manager (EnvironmentManager): Environment manager instance\n",
        "        \"\"\"\n",
        "        self.env = env_manager\n",
        "        self.cfg = env_manager.get_config()\n",
        "        self.logger = env_manager.get_logger()\n",
        "        self.distributed = env_manager.distributed\n",
        "        self.local_rank = env_manager.local_rank\n",
        "\n",
        "        self.model = None\n",
        "        self.raw_model = None\n",
        "\n",
        "    def initialize(self):\n",
        "        \"\"\"Initialize the model and load weights if specified.\"\"\"\n",
        "        self._build_model()\n",
        "        self._load_checkpoint()\n",
        "        return self.model\n",
        "\n",
        "    def _build_model(self):\n",
        "        \"\"\"Build and initialize the segmentation model.\"\"\"\n",
        "        # Import model definitions (ensure this is available in your project)\n",
        "        try:\n",
        "            import model\n",
        "        except ImportError:\n",
        "            self.logger.warning(\"Could not import model module. Assuming model definitions are registered.\")\n",
        "\n",
        "        # Build model from config\n",
        "        self.model = build_segmentor(self.cfg.model)\n",
        "        self.model.init_weights()\n",
        "\n",
        "        # Log model size\n",
        "        n_parameters = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "        self.logger.info(f'Number of trainable parameters: {n_parameters:,}')\n",
        "\n",
        "        # Setup distributed training if needed\n",
        "        if self.distributed:\n",
        "            self._setup_distributed_model()\n",
        "        else:\n",
        "            self.model = self.model.cuda()\n",
        "            self.raw_model = self.model\n",
        "\n",
        "        self.logger.info('Model initialization complete')\n",
        "\n",
        "    def _setup_distributed_model(self):\n",
        "        \"\"\"Setup model for distributed training with SyncBN if needed.\"\"\"\n",
        "        # Convert to SyncBN if specified\n",
        "        if self.cfg.get('syncBN', True):\n",
        "            self.model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(self.model)\n",
        "            self.logger.info('Converted to SyncBatchNorm')\n",
        "\n",
        "        # Setup DDP\n",
        "        find_unused_parameters = self.cfg.get('find_unused_parameters', False)\n",
        "        ddp_model_module = torch.nn.parallel.DistributedDataParallel\n",
        "        self.model = ddp_model_module(\n",
        "            self.model.cuda(),\n",
        "            device_ids=[torch.cuda.current_device()],\n",
        "            broadcast_buffers=False,\n",
        "            find_unused_parameters=find_unused_parameters\n",
        "        )\n",
        "        self.raw_model = self.model.module\n",
        "\n",
        "    def _load_checkpoint(self):\n",
        "        \"\"\"Resume from checkpoint or load pre-trained weights.\"\"\"\n",
        "        # Check for latest checkpoint\n",
        "        self.cfg.resume_from = ''\n",
        "        if osp.exists(osp.join(self.env.args.work_dir, 'latest.pth')):\n",
        "            self.cfg.resume_from = osp.join(self.env.args.work_dir, 'latest.pth')\n",
        "\n",
        "        # Override with command line argument if provided\n",
        "        if self.env.args.resume_from:\n",
        "            self.cfg.resume_from = self.env.args.resume_from\n",
        "\n",
        "        self.logger.info(f'Resume from: {self.cfg.resume_from}')\n",
        "        self.logger.info(f'Work directory: {self.env.args.work_dir}')\n",
        "\n",
        "        # Load checkpoint if available\n",
        "        if self.cfg.resume_from and osp.exists(self.cfg.resume_from):\n",
        "            self._load_from_checkpoint(self.cfg.resume_from)\n",
        "        # Otherwise load from pretrained weights if specified\n",
        "        elif hasattr(self.cfg, 'load_from') and self.cfg.load_from:\n",
        "            self._load_from_pretrained(self.cfg.load_from)\n",
        "\n",
        "    def _load_from_checkpoint(self, checkpoint_path):\n",
        "        \"\"\"Load model from checkpoint.\"\"\"\n",
        "        try:\n",
        "            map_location = 'cpu'\n",
        "            ckpt = torch.load(checkpoint_path, map_location=map_location)\n",
        "            self.raw_model.load_state_dict(ckpt.get(\"state_dict\", ckpt), strict=True)\n",
        "            self.logger.info(f'Successfully resumed from {checkpoint_path}')\n",
        "        except Exception as e:\n",
        "            self.logger.error(f'Failed to load checkpoint: {str(e)}')\n",
        "            raise\n",
        "\n",
        "    def _load_from_pretrained(self, pretrained_path):\n",
        "        \"\"\"Load pretrained weights.\"\"\"\n",
        "        try:\n",
        "            ckpt = torch.load(pretrained_path, map_location='cpu')\n",
        "            state_dict = ckpt.get('state_dict', ckpt)\n",
        "\n",
        "            try:\n",
        "                load_info = self.raw_model.load_state_dict(state_dict, strict=False)\n",
        "                self.logger.info(f'Loaded pretrained weights: {load_info}')\n",
        "            except Exception:\n",
        "                # Try with weight refinement if regular loading fails\n",
        "                from misc.checkpoint_util import refine_load_from_sd\n",
        "                refined_state_dict = refine_load_from_sd(state_dict)\n",
        "                load_info = self.raw_model.load_state_dict(refined_state_dict, strict=False)\n",
        "                self.logger.info(f'Loaded pretrained weights with refinement: {load_info}')\n",
        "        except Exception as e:\n",
        "            self.logger.error(f'Failed to load pretrained weights: {str(e)}')\n",
        "            raise\n",
        "\n",
        "    def get_model(self):\n",
        "        \"\"\"Get the initialized model.\"\"\"\n",
        "        return self.model\n",
        "\n",
        "\n",
        "class DatasetManager:\n",
        "    \"\"\"Handles dataset loading and preparation.\"\"\"\n",
        "\n",
        "    def __init__(self, env_manager):\n",
        "        \"\"\"\n",
        "        Initialize the dataset manager.\n",
        "\n",
        "        Args:\n",
        "            env_manager (EnvironmentManager): Environment manager instance\n",
        "        \"\"\"\n",
        "        self.env = env_manager\n",
        "        self.cfg = env_manager.get_config()\n",
        "        self.logger = env_manager.get_logger()\n",
        "        self.distributed = env_manager.distributed\n",
        "\n",
        "        self.train_loader = None\n",
        "        self.val_loader = None\n",
        "\n",
        "    def load_datasets(self, val_only=True):\n",
        "        \"\"\"\n",
        "        Load datasets and create data loaders.\n",
        "\n",
        "        Args:\n",
        "            val_only (bool): Whether to only load validation data\n",
        "\n",
        "        Returns:\n",
        "            tuple: (train_loader, val_loader) - DataLoader instances\n",
        "        \"\"\"\n",
        "        try:\n",
        "            from dataset import get_dataloader\n",
        "\n",
        "            self.train_loader, self.val_loader = get_dataloader(\n",
        "                self.cfg.train_dataset_config,\n",
        "                self.cfg.val_dataset_config,\n",
        "                self.cfg.train_loader,\n",
        "                self.cfg.val_loader,\n",
        "                dist=self.distributed,\n",
        "                val_only=val_only\n",
        "            )\n",
        "\n",
        "            self.logger.info('Dataset loaded successfully')\n",
        "\n",
        "            if val_only:\n",
        "                self.logger.info(f'Validation dataset size: {len(self.val_loader)}')\n",
        "            else:\n",
        "                self.logger.info(f'Training dataset size: {len(self.train_loader)}')\n",
        "                self.logger.info(f'Validation dataset size: {len(self.val_loader)}')\n",
        "\n",
        "            return self.train_loader, self.val_loader\n",
        "        except Exception as e:\n",
        "            self.logger.error(f'Failed to load dataset: {str(e)}')\n",
        "            raise\n",
        "\n",
        "    def get_val_loader(self):\n",
        "        \"\"\"Get validation data loader.\"\"\"\n",
        "        return self.val_loader\n",
        "\n",
        "\n",
        "class Evaluator:\n",
        "    \"\"\"Handles model evaluation and metrics computation.\"\"\"\n",
        "\n",
        "    def __init__(self, env_manager, model_manager, dataset_manager):\n",
        "        \"\"\"\n",
        "        Initialize the evaluator.\n",
        "\n",
        "        Args:\n",
        "            env_manager (EnvironmentManager): Environment manager instance\n",
        "            model_manager (ModelManager): Model manager instance\n",
        "            dataset_manager (DatasetManager): Dataset manager instance\n",
        "        \"\"\"\n",
        "        self.env = env_manager\n",
        "        self.model_manager = model_manager\n",
        "        self.dataset_manager = dataset_manager\n",
        "\n",
        "        self.cfg = env_manager.get_config()\n",
        "        self.logger = env_manager.get_logger()\n",
        "        self.local_rank = env_manager.local_rank\n",
        "        self.args = env_manager.args\n",
        "\n",
        "        self.model = model_manager.get_model()\n",
        "        self.val_loader = dataset_manager.get_val_loader()\n",
        "\n",
        "    def evaluate(self):\n",
        "        \"\"\"\n",
        "        Run model evaluation.\n",
        "\n",
        "        Returns:\n",
        "            dict: Dictionary containing evaluation metrics\n",
        "        \"\"\"\n",
        "        print_freq = self.cfg.print_freq\n",
        "\n",
        "        # Initialize metrics\n",
        "        miou_metric = self._setup_metrics()\n",
        "\n",
        "        # Set model to evaluation mode\n",
        "        self.model.eval()\n",
        "        os.environ['eval'] = 'true'\n",
        "\n",
        "        self.logger.info('Starting evaluation...')\n",
        "        with torch.no_grad():\n",
        "            for i_iter_val, data in enumerate(self.val_loader):\n",
        "                # Process batch\n",
        "                result_dict = self._process_batch(data)\n",
        "\n",
        "                # Handle occupancy predictions\n",
        "                if 'final_occ' in result_dict:\n",
        "                    self._process_occupancy(result_dict, miou_metric, i_iter_val)\n",
        "\n",
        "                # Log progress\n",
        "                if i_iter_val % print_freq == 0 and self.env.is_master():\n",
        "                    self.logger.info(f'[EVAL] Iter {i_iter_val:5d}')\n",
        "\n",
        "        # Compute and log final metrics\n",
        "        miou, iou2 = miou_metric._after_epoch()\n",
        "        self.logger.info(f'Evaluation results - mIoU: {miou:.4f}, iou2: {iou2:.4f}')\n",
        "        miou_metric.reset()\n",
        "\n",
        "        return {'miou': miou, 'iou2': iou2}\n",
        "\n",
        "    def _setup_metrics(self):\n",
        "        \"\"\"Setup evaluation metrics.\"\"\"\n",
        "        from misc.metric_util import MeanIoU\n",
        "\n",
        "        class_names = [\n",
        "            'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle',\n",
        "            'motorcycle', 'pedestrian', 'traffic_cone', 'trailer', 'truck',\n",
        "            'driveable_surface', 'other_flat', 'sidewalk', 'terrain', 'manmade',\n",
        "            'vegetation'\n",
        "        ]\n",
        "\n",
        "        miou_metric = MeanIoU(\n",
        "            list(range(1, 17)),  # Classes\n",
        "            17,                  # Number of classes\n",
        "            class_names,         # Class names for logging\n",
        "            True,                # Use class weights\n",
        "            17,                  # Ignore index\n",
        "            filter_minmax=False  # Don't filter min/max values\n",
        "        )\n",
        "        miou_metric.reset()\n",
        "        return miou_metric\n",
        "\n",
        "    def _process_batch(self, data):\n",
        "        \"\"\"\n",
        "        Process a single batch of data.\n",
        "\n",
        "        Args:\n",
        "            data (dict): Batch data dictionary\n",
        "\n",
        "        Returns:\n",
        "            dict: Result dictionary from model inference\n",
        "        \"\"\"\n",
        "        # Move tensors to GPU\n",
        "        for k in list(data.keys()):\n",
        "            if isinstance(data[k], torch.Tensor):\n",
        "                data[k] = data[k].cuda()\n",
        "\n",
        "        # Extract images and forward pass\n",
        "        input_imgs = data.pop('img')\n",
        "        return self.model(imgs=input_imgs, metas=data)\n",
        "\n",
        "    def _process_occupancy(self, result_dict, miou_metric, iter_idx):\n",
        "        \"\"\"\n",
        "        Process occupancy predictions and update metrics.\n",
        "\n",
        "        Args:\n",
        "            result_dict (dict): Model output dictionary\n",
        "            miou_metric (MeanIoU): Metric instance\n",
        "            iter_idx (int): Iteration index for visualization\n",
        "        \"\"\"\n",
        "        for idx, pred in enumerate(result_dict['final_occ']):\n",
        "            pred_occ = pred\n",
        "            gt_occ = result_dict['sampled_label'][idx]\n",
        "            occ_mask = result_dict['occ_mask'][idx].flatten()\n",
        "\n",
        "            # Visualize occupancy if requested\n",
        "            if self.args.vis_occ:\n",
        "                self._visualize_occupancy(pred_occ, gt_occ, iter_idx)\n",
        "\n",
        "            # Update metrics\n",
        "            miou_metric._after_step(pred_occ, gt_occ, occ_mask)\n",
        "\n",
        "    def _visualize_occupancy(self, pred_occ, gt_occ, iter_idx):\n",
        "        \"\"\"\n",
        "        Visualize occupancy predictions.\n",
        "\n",
        "        Args:\n",
        "            pred_occ (torch.Tensor): Predicted occupancy\n",
        "            gt_occ (torch.Tensor): Ground truth occupancy\n",
        "            iter_idx (int): Iteration index for naming\n",
        "        \"\"\"\n",
        "        try:\n",
        "            from vis import save_occ\n",
        "\n",
        "            vis_dir = os.path.join(self.args.work_dir, 'vis')\n",
        "            os.makedirs(vis_dir, exist_ok=True)\n",
        "\n",
        "            # Save prediction visualization\n",
        "            save_occ(\n",
        "                vis_dir,\n",
        "                pred_occ.reshape(1, 200, 200, 16),\n",
        "                f'val_{iter_idx}_pred',\n",
        "                True, 0\n",
        "            )\n",
        "\n",
        "            # Save ground truth visualization\n",
        "            save_occ(\n",
        "                vis_dir,\n",
        "                gt_occ.reshape(1, 200, 200, 16),\n",
        "                f'val_{iter_idx}_gt',\n",
        "                True, 0\n",
        "            )\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f'Visualization failed: {str(e)}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "mr1mADm50b5V"
      },
      "outputs": [],
      "source": [
        "class EnvironmentManager:\n",
        "    \"\"\"Handles environment setup, configuration, distributed processing, and logging.\"\"\"\n",
        "\n",
        "    def __init__(self, local_rank, args):\n",
        "        \"\"\"\n",
        "        Initialize environment settings and logging.\n",
        "\n",
        "        Args:\n",
        "            local_rank (int): Local rank for distributed processing\n",
        "            args (argparse.Namespace): Command line arguments\n",
        "        \"\"\"\n",
        "        self.local_rank = local_rank\n",
        "        self.args = args\n",
        "        self.distributed = False\n",
        "        self.cfg = None\n",
        "        self.logger = None\n",
        "\n",
        "        # Setup environment in sequence\n",
        "        self._setup_environment()\n",
        "        self._load_config()\n",
        "        self._setup_distributed()\n",
        "        self._setup_logging()\n",
        "\n",
        "    def _setup_environment(self):\n",
        "        \"\"\"Set up environment variables and random seeds for reproducibility.\"\"\"\n",
        "        set_random_seed(self.args.seed)\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    def _load_config(self):\n",
        "        \"\"\"Load configuration from file.\"\"\"\n",
        "        self.cfg = Config.fromfile(self.args.py_config)\n",
        "        self.cfg.work_dir = self.args.work_dir\n",
        "\n",
        "        # Ensure work directory exists\n",
        "        os.makedirs(self.args.work_dir, exist_ok=True)\n",
        "\n",
        "    def _setup_distributed(self):\n",
        "        \"\"\"Set up distributed data parallel processing if multiple GPUs are available.\"\"\"\n",
        "        if self.args.gpus > 1:\n",
        "            self.distributed = True\n",
        "\n",
        "            # Get environment variables for distributed setup\n",
        "            ip = os.environ.get(\"MASTER_ADDR\", \"127.0.0.1\")\n",
        "            port = os.environ.get(\"MASTER_PORT\", \"20507\")\n",
        "            hosts = int(os.environ.get(\"WORLD_SIZE\", 1))  # number of nodes\n",
        "            rank = int(os.environ.get(\"RANK\", 0))  # node id\n",
        "            gpus = torch.cuda.device_count()  # gpus per node\n",
        "\n",
        "            if self.local_rank == 0:\n",
        "                print(f\"Initializing DDP: tcp://{ip}:{port}\")\n",
        "\n",
        "            # Initialize process group\n",
        "            dist.init_process_group(\n",
        "                backend=\"nccl\",\n",
        "                init_method=f\"tcp://{ip}:{port}\",\n",
        "                world_size=hosts * gpus,\n",
        "                rank=rank * gpus + self.local_rank\n",
        "            )\n",
        "\n",
        "            world_size = dist.get_world_size()\n",
        "            self.cfg.gpu_ids = range(world_size)\n",
        "            torch.cuda.set_device(self.local_rank)\n",
        "\n",
        "            # Suppress prints on non-master processes\n",
        "            if self.local_rank != 0:\n",
        "                import builtins\n",
        "                builtins.print = self.pass_print\n",
        "        else:\n",
        "            self.distributed = False\n",
        "\n",
        "    def _setup_logging(self):\n",
        "        \"\"\"Set up logging with timestamp.\"\"\"\n",
        "        timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
        "        log_file = osp.join(self.args.work_dir, f'{timestamp}.log')\n",
        "        self.logger = MMLogger('selfocc', log_file=log_file)\n",
        "        MMLogger._instance_dict['selfocc'] = self.logger\n",
        "\n",
        "        if self.local_rank == 0:\n",
        "            self.logger.info(f\"Configuration:\\n{self.cfg.pretty_text}\")\n",
        "\n",
        "    def pass_print(self, *args, **kwargs):\n",
        "        \"\"\"Empty print function for non-master processes.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def is_master(self):\n",
        "        \"\"\"Check if this process is the master process.\"\"\"\n",
        "        return self.local_rank == 0\n",
        "\n",
        "    def get_logger(self):\n",
        "        \"\"\"Get the logger instance.\"\"\"\n",
        "        return self.logger\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"Get the configuration instance.\"\"\"\n",
        "        return self.cfg\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "15hSE-Oh1EUt"
      },
      "outputs": [],
      "source": [
        "class ModelManager:\n",
        "    \"\"\"Handles model creation, initialization, and checkpoint loading.\"\"\"\n",
        "\n",
        "    def __init__(self, env_manager):\n",
        "        \"\"\"\n",
        "        Initialize the model manager.\n",
        "\n",
        "        Args:\n",
        "            env_manager (EnvironmentManager): Environment manager instance\n",
        "        \"\"\"\n",
        "        self.env = env_manager\n",
        "        self.cfg = env_manager.get_config()\n",
        "        self.logger = env_manager.get_logger()\n",
        "        self.distributed = env_manager.distributed\n",
        "        self.local_rank = env_manager.local_rank\n",
        "\n",
        "        self.model = None\n",
        "        self.raw_model = None\n",
        "\n",
        "    def initialize(self):\n",
        "        \"\"\"Initialize the model and load weights if specified.\"\"\"\n",
        "        self._build_model()\n",
        "        # self._load_checkpoint()\n",
        "        return self.model\n",
        "\n",
        "    def _build_model(self):\n",
        "        \"\"\"Build and initialize the segmentation model.\"\"\"\n",
        "        # Import model definitions (ensure this is available in your project)\n",
        "        try:\n",
        "            import model\n",
        "        except ImportError:\n",
        "            self.logger.warning(\"Could not import model module. Assuming model definitions are registered.\")\n",
        "\n",
        "        # Build model from config\n",
        "        self.model = build_segmentor(self.cfg.model)\n",
        "        self.model.init_weights()\n",
        "\n",
        "        # Log model size\n",
        "        n_parameters = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "        self.logger.info(f'Number of trainable parameters: {n_parameters:,}')\n",
        "\n",
        "        # Setup distributed training if needed\n",
        "        if self.distributed:\n",
        "            print(\"DISTRIBUTED\")\n",
        "            self._setup_distributed_model()\n",
        "        else:\n",
        "            print(\"NOT DISTRIBUTED\")\n",
        "            self.model = self.model.cuda()\n",
        "            self.raw_model = self.model\n",
        "\n",
        "        self.logger.info('Model initialization complete')\n",
        "\n",
        "    def _setup_distributed_model(self):\n",
        "        \"\"\"Setup model for distributed training with SyncBN if needed.\"\"\"\n",
        "        # Convert to SyncBN if specified\n",
        "        if self.cfg.get('syncBN', True):\n",
        "            self.model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(self.model)\n",
        "            self.logger.info('Converted to SyncBatchNorm')\n",
        "\n",
        "        # Setup DDP\n",
        "        find_unused_parameters = self.cfg.get('find_unused_parameters', False)\n",
        "        ddp_model_module = torch.nn.parallel.DistributedDataParallel\n",
        "        self.model = ddp_model_module(\n",
        "            self.model.cuda(),\n",
        "            device_ids=[torch.cuda.current_device()],\n",
        "            broadcast_buffers=False,\n",
        "            find_unused_parameters=find_unused_parameters\n",
        "        )\n",
        "        self.raw_model = self.model.module\n",
        "\n",
        "    def _load_checkpoint(self):\n",
        "        \"\"\"Resume from checkpoint or load pre-trained weights.\"\"\"\n",
        "        # Check for latest checkpoint\n",
        "        self.cfg.resume_from = ''\n",
        "        if osp.exists(osp.join(self.env.args.work_dir, 'latest.pth')):\n",
        "            self.cfg.resume_from = osp.join(self.env.args.work_dir, 'latest.pth')\n",
        "\n",
        "        # Override with command line argument if provided\n",
        "        if self.env.args.resume_from:\n",
        "            self.cfg.resume_from = self.env.args.resume_from\n",
        "\n",
        "        self.logger.info(f'Resume from: {self.cfg.resume_from}')\n",
        "        self.logger.info(f'Work directory: {self.env.args.work_dir}')\n",
        "\n",
        "        # Load checkpoint if available\n",
        "        if self.cfg.resume_from and osp.exists(self.cfg.resume_from):\n",
        "            print(f'Loading checkpoint from {self.cfg.resume_from}')\n",
        "            self._load_from_checkpoint(self.cfg.resume_from)\n",
        "        # Otherwise load from pretrained weights if specified\n",
        "        elif hasattr(self.cfg, 'load_from') and self.cfg.load_from:\n",
        "            self._load_from_pretrained(self.cfg.load_from)\n",
        "\n",
        "    def _load_from_checkpoint(self, checkpoint_path):\n",
        "        \"\"\"Load model from checkpoint.\"\"\"\n",
        "        try:\n",
        "            # Use GPU for loading\n",
        "            map_location = 'cpu'\n",
        "            ckpt = torch.load(checkpoint_path, map_location=map_location)\n",
        "            \n",
        "            # First try loading with strict=False\n",
        "            try:\n",
        "                self.raw_model.load_state_dict(ckpt.get(\"state_dict\", ckpt), strict=True)\n",
        "                self.logger.info(f'Successfully resumed from {checkpoint_path}')\n",
        "                # self.logger.info(f'Missing keys: {len(load_info.missing_keys)}, Unexpected keys: {len(load_info.unexpected_keys)}')\n",
        "            except Exception as inner_e:\n",
        "                # If regular loading fails, try with weight refinement\n",
        "                self.logger.warning(f'Regular loading failed, trying with refinement: {str(inner_e)}')\n",
        "                from misc.checkpoint_util import refine_load_from_sd\n",
        "                state_dict = ckpt.get(\"state_dict\", ckpt)\n",
        "                refined_state_dict = refine_load_from_sd(state_dict)\n",
        "                load_info = self.raw_model.load_state_dict(refined_state_dict, strict=False)\n",
        "                self.logger.info(f'Successfully resumed from {checkpoint_path} with refinement')\n",
        "                self.logger.info(f'Missing keys: {len(load_info.missing_keys)}, Unexpected keys: {len(load_info.unexpected_keys)}')\n",
        "        except Exception as e:\n",
        "            self.logger.error(f'Failed to load checkpoint: {str(e)}')\n",
        "            raise\n",
        "\n",
        "    def _load_from_pretrained(self, pretrained_path):\n",
        "        \"\"\"Load pretrained weights.\"\"\"\n",
        "        try:\n",
        "            # Use GPU for loading\n",
        "            map_location = f'cuda:{torch.cuda.current_device()}'\n",
        "            ckpt = torch.load(pretrained_path, map_location=map_location)\n",
        "            state_dict = ckpt.get('state_dict', ckpt)\n",
        "\n",
        "            try:\n",
        "                load_info = self.raw_model.load_state_dict(state_dict, strict=True)\n",
        "                missing_keys = len(load_info.missing_keys)\n",
        "                unexpected_keys = len(load_info.unexpected_keys)\n",
        "                self.logger.info(f'Loaded pretrained weights: missing keys: {missing_keys}, unexpected keys: {unexpected_keys}')\n",
        "            except Exception as inner_e:\n",
        "                # Try with weight refinement if regular loading fails\n",
        "                self.logger.warning(f'Regular loading failed, trying with refinement: {str(inner_e)}')\n",
        "                from misc.checkpoint_util import refine_load_from_sd\n",
        "                refined_state_dict = refine_load_from_sd(state_dict)\n",
        "                load_info = self.raw_model.load_state_dict(refined_state_dict, strict=False)\n",
        "                missing_keys = len(load_info.missing_keys)\n",
        "                unexpected_keys = len(load_info.unexpected_keys)\n",
        "                self.logger.info(f'Loaded pretrained weights with refinement: missing keys: {missing_keys}, unexpected keys: {unexpected_keys}')\n",
        "        except Exception as e:\n",
        "            self.logger.error(f'Failed to load pretrained weights: {str(e)}')\n",
        "            raise\n",
        "\n",
        "    def get_model(self):\n",
        "        \"\"\"Get the initialized model.\"\"\"\n",
        "        return self.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "jnr4bcqJ0unU"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import torch\n",
        "\n",
        "# Create a dummy args object with the desired attributes.\n",
        "args = argparse.Namespace(\n",
        "    py_config='config/nuscenes_gs25600_solid.py',\n",
        "    work_dir='out',\n",
        "    resume_from='downloads/nonempty/nonempty.pth',\n",
        "    seed=42,\n",
        "    gpus=torch.cuda.device_count(),\n",
        "    vis_occ=False\n",
        ")\n",
        "\n",
        "# EnvironmentManager(0, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OniYylv3V5io",
        "outputId": "391c21c9-9a2f-426a-b5d3-d2a0e54f7410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "03/17 06:36:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Configuration:\n",
            "anno_root = 'data/nuscenes_cam/'\n",
            "batch_size = 1\n",
            "data_aug_conf = dict(\n",
            "    H=900,\n",
            "    W=1600,\n",
            "    bot_pct_lim=(\n",
            "        0.0,\n",
            "        0.0,\n",
            "    ),\n",
            "    final_dim=(\n",
            "        864,\n",
            "        1600,\n",
            "    ),\n",
            "    rand_flip=True,\n",
            "    resize_lim=(\n",
            "        1.0,\n",
            "        1.0,\n",
            "    ),\n",
            "    rot_lim=(\n",
            "        0.0,\n",
            "        0.0,\n",
            "    ))\n",
            "data_root = 'data/nuscenes/'\n",
            "drop_out = 0.1\n",
            "embed_dims = 128\n",
            "grad_max_norm = 35\n",
            "img_norm_cfg = dict(\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    to_rgb=True)\n",
            "include_opa = True\n",
            "input_shape = (\n",
            "    1600,\n",
            "    864,\n",
            ")\n",
            "load_from = 'ckpts/r101_dcn_fcos3d_pretrain.pth'\n",
            "loss = dict(\n",
            "    loss_cfgs=[\n",
            "        dict(\n",
            "            balance_cls_weight=True,\n",
            "            empty_label=17,\n",
            "            lovasz_ignore=17,\n",
            "            manual_class_weight=[\n",
            "                1.01552756,\n",
            "                1.06897009,\n",
            "                1.30013094,\n",
            "                1.07253735,\n",
            "                0.94637502,\n",
            "                1.10087012,\n",
            "                1.26960524,\n",
            "                1.06258364,\n",
            "                1.189019,\n",
            "                1.06217292,\n",
            "                1.00595144,\n",
            "                0.85706115,\n",
            "                1.03923299,\n",
            "                0.90867526,\n",
            "                0.8936431,\n",
            "                0.85486129,\n",
            "                0.8527829,\n",
            "                0.5,\n",
            "            ],\n",
            "            multi_loss_weights=dict(\n",
            "                loss_voxel_ce_weight=10.0, loss_voxel_lovasz_weight=1.0),\n",
            "            num_classes=18,\n",
            "            type='OccupancyLoss',\n",
            "            use_dice_loss=False,\n",
            "            use_focal_loss=False,\n",
            "            use_lovasz_loss=True,\n",
            "            use_sem_geo_scal_loss=False,\n",
            "            weight=1.0),\n",
            "    ],\n",
            "    type='MultiLoss')\n",
            "loss_input_convertion = dict(\n",
            "    occ_mask='occ_mask',\n",
            "    pred_occ='pred_occ',\n",
            "    sampled_label='sampled_label',\n",
            "    sampled_xyz='sampled_xyz')\n",
            "max_epochs = 20\n",
            "model = dict(\n",
            "    encoder=dict(\n",
            "        anchor_encoder=dict(\n",
            "            embed_dims=128,\n",
            "            include_opa=True,\n",
            "            semantic_dim=17,\n",
            "            semantics=True,\n",
            "            type='SparseGaussian3DEncoder'),\n",
            "        deformable_model=dict(\n",
            "            attn_drop=0.15,\n",
            "            embed_dims=128,\n",
            "            kps_generator=dict(\n",
            "                embed_dims=128,\n",
            "                fix_scale=[\n",
            "                    [\n",
            "                        0,\n",
            "                        0,\n",
            "                        0,\n",
            "                    ],\n",
            "                    [\n",
            "                        0.45,\n",
            "                        0,\n",
            "                        0,\n",
            "                    ],\n",
            "                    [\n",
            "                        -0.45,\n",
            "                        0,\n",
            "                        0,\n",
            "                    ],\n",
            "                    [\n",
            "                        0,\n",
            "                        0.45,\n",
            "                        0,\n",
            "                    ],\n",
            "                    [\n",
            "                        0,\n",
            "                        -0.45,\n",
            "                        0,\n",
            "                    ],\n",
            "                    [\n",
            "                        0,\n",
            "                        0,\n",
            "                        0.45,\n",
            "                    ],\n",
            "                    [\n",
            "                        0,\n",
            "                        0,\n",
            "                        -0.45,\n",
            "                    ],\n",
            "                ],\n",
            "                num_learnable_pts=2,\n",
            "                pc_range=[\n",
            "                    -50.0,\n",
            "                    -50.0,\n",
            "                    -5.0,\n",
            "                    50.0,\n",
            "                    50.0,\n",
            "                    3.0,\n",
            "                ],\n",
            "                phi_activation='sigmoid',\n",
            "                scale_range=[\n",
            "                    0.08,\n",
            "                    0.64,\n",
            "                ],\n",
            "                type='SparseGaussian3DKeyPointsGenerator',\n",
            "                xyz_coordinate='cartesian'),\n",
            "            num_cams=6,\n",
            "            num_groups=4,\n",
            "            num_levels=4,\n",
            "            residual_mode='cat',\n",
            "            type='DeformableFeatureAggregation',\n",
            "            use_camera_embed=True,\n",
            "            use_deformable_func=True),\n",
            "        ffn=dict(\n",
            "            act_cfg=dict(inplace=True, type='ReLU'),\n",
            "            embed_dims=128,\n",
            "            feedforward_channels=512,\n",
            "            ffn_drop=0.1,\n",
            "            in_channels=256,\n",
            "            num_fcs=2,\n",
            "            pre_norm=dict(type='LN'),\n",
            "            type='AsymmetricFFN'),\n",
            "        norm_layer=dict(normalized_shape=128, type='LN'),\n",
            "        num_decoder=4,\n",
            "        num_single_frame_decoder=1,\n",
            "        operation_order=[\n",
            "            'deformable',\n",
            "            'ffn',\n",
            "            'norm',\n",
            "            'refine',\n",
            "            'spconv',\n",
            "            'norm',\n",
            "            'deformable',\n",
            "            'ffn',\n",
            "            'norm',\n",
            "            'refine',\n",
            "            'spconv',\n",
            "            'norm',\n",
            "            'deformable',\n",
            "            'ffn',\n",
            "            'norm',\n",
            "            'refine',\n",
            "            'spconv',\n",
            "            'norm',\n",
            "            'deformable',\n",
            "            'ffn',\n",
            "            'norm',\n",
            "            'refine',\n",
            "        ],\n",
            "        refine_layer=dict(\n",
            "            embed_dims=128,\n",
            "            include_opa=True,\n",
            "            pc_range=[\n",
            "                -50.0,\n",
            "                -50.0,\n",
            "                -5.0,\n",
            "                50.0,\n",
            "                50.0,\n",
            "                3.0,\n",
            "            ],\n",
            "            phi_activation='sigmoid',\n",
            "            refine_manual=[\n",
            "                0,\n",
            "                1,\n",
            "                2,\n",
            "            ],\n",
            "            restrict_xyz=True,\n",
            "            scale_range=[\n",
            "                0.08,\n",
            "                0.64,\n",
            "            ],\n",
            "            semantic_dim=17,\n",
            "            semantics=True,\n",
            "            semantics_activation='softplus',\n",
            "            type='SparseGaussian3DRefinementModule',\n",
            "            unit_xyz=[\n",
            "                4.0,\n",
            "                4.0,\n",
            "                1.0,\n",
            "            ],\n",
            "            xyz_coordinate='cartesian'),\n",
            "        spconv_layer=dict(\n",
            "            embed_channels=128,\n",
            "            grid_size=[\n",
            "                0.5,\n",
            "                0.5,\n",
            "                0.5,\n",
            "            ],\n",
            "            in_channels=128,\n",
            "            pc_range=[\n",
            "                -50.0,\n",
            "                -50.0,\n",
            "                -5.0,\n",
            "                50.0,\n",
            "                50.0,\n",
            "                3.0,\n",
            "            ],\n",
            "            phi_activation='sigmoid',\n",
            "            type='SparseConv3D',\n",
            "            use_out_proj=True,\n",
            "            xyz_coordinate='cartesian'),\n",
            "        type='GaussianOccEncoder'),\n",
            "    head=dict(\n",
            "        apply_loss_type='random_1',\n",
            "        cuda_kwargs=dict(\n",
            "            D=16,\n",
            "            H=200,\n",
            "            W=200,\n",
            "            grid_size=0.5,\n",
            "            pc_min=[\n",
            "                -50.0,\n",
            "                -50.0,\n",
            "                -5.0,\n",
            "            ],\n",
            "            scale_multiplier=3),\n",
            "        empty_args=dict(mean=[\n",
            "            0,\n",
            "            0,\n",
            "            -1.0,\n",
            "        ], scale=[\n",
            "            100,\n",
            "            100,\n",
            "            8.0,\n",
            "        ]),\n",
            "        num_classes=18,\n",
            "        type='GaussianHead',\n",
            "        with_empty=True),\n",
            "    img_backbone=dict(\n",
            "        dcn=dict(deform_groups=1, fallback_on_stride=False, type='DCNv2'),\n",
            "        depth=101,\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(requires_grad=False, type='BN2d'),\n",
            "        norm_eval=True,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        stage_with_dcn=(\n",
            "            False,\n",
            "            False,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        style='caffe',\n",
            "        type='ResNet',\n",
            "        with_cp=True),\n",
            "    img_backbone_out_indices=[\n",
            "        0,\n",
            "        1,\n",
            "        2,\n",
            "        3,\n",
            "    ],\n",
            "    img_neck=dict(\n",
            "        add_extra_convs='on_output',\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "            2048,\n",
            "        ],\n",
            "        num_outs=4,\n",
            "        out_channels=128,\n",
            "        relu_before_extra_convs=True,\n",
            "        start_level=1,\n",
            "        type='FPN'),\n",
            "    lifter=dict(\n",
            "        anchor_grad=True,\n",
            "        embed_dims=128,\n",
            "        feat_grad=False,\n",
            "        include_opa=True,\n",
            "        num_anchor=25600,\n",
            "        phi_activation='sigmoid',\n",
            "        semantic_dim=17,\n",
            "        semantics=True,\n",
            "        type='GaussianLifter'),\n",
            "    type='BEVSegmentor')\n",
            "num_decoder = 4\n",
            "num_groups = 4\n",
            "num_levels = 4\n",
            "num_single_frame_decoder = 1\n",
            "occ_path = 'data/surroundocc/samples'\n",
            "optimizer = dict(\n",
            "    optimizer=dict(lr=0.0002, type='AdamW', weight_decay=0.01),\n",
            "    paramwise_cfg=dict(custom_keys=dict(img_backbone=dict(lr_mult=0.1))))\n",
            "pc_range = [\n",
            "    -50.0,\n",
            "    -50.0,\n",
            "    -5.0,\n",
            "    50.0,\n",
            "    50.0,\n",
            "    3.0,\n",
            "]\n",
            "phi_activation = 'sigmoid'\n",
            "print_freq = 50\n",
            "scale_range = [\n",
            "    0.08,\n",
            "    0.64,\n",
            "]\n",
            "semantic_dim = 17\n",
            "semantics = True\n",
            "test_pipeline = [\n",
            "    dict(to_float32=True, type='LoadMultiViewImageFromFiles'),\n",
            "    dict(\n",
            "        occ_path='data/surroundocc/samples',\n",
            "        semantic=True,\n",
            "        type='LoadOccupancySurroundOcc',\n",
            "        use_ego=False),\n",
            "    dict(type='ResizeCropFlipImage'),\n",
            "    dict(\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        to_rgb=True,\n",
            "        type='NormalizeMultiviewImage'),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(num_cams=6, type='NuScenesAdaptor', use_ego=False),\n",
            "]\n",
            "train_dataset_config = dict(\n",
            "    data_aug_conf=dict(\n",
            "        H=900,\n",
            "        W=1600,\n",
            "        bot_pct_lim=(\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ),\n",
            "        final_dim=(\n",
            "            864,\n",
            "            1600,\n",
            "        ),\n",
            "        rand_flip=True,\n",
            "        resize_lim=(\n",
            "            1.0,\n",
            "            1.0,\n",
            "        ),\n",
            "        rot_lim=(\n",
            "            0.0,\n",
            "            0.0,\n",
            "        )),\n",
            "    data_root='data/nuscenes/',\n",
            "    imageset='data/nuscenes_cam/nuscenes_infos_train_sweeps_occ.pkl',\n",
            "    phase='train',\n",
            "    pipeline=[\n",
            "        dict(to_float32=True, type='LoadMultiViewImageFromFiles'),\n",
            "        dict(\n",
            "            occ_path='data/surroundocc/samples',\n",
            "            semantic=True,\n",
            "            type='LoadOccupancySurroundOcc',\n",
            "            use_ego=False),\n",
            "        dict(type='ResizeCropFlipImage'),\n",
            "        dict(type='PhotoMetricDistortionMultiViewImage'),\n",
            "        dict(\n",
            "            mean=[\n",
            "                123.675,\n",
            "                116.28,\n",
            "                103.53,\n",
            "            ],\n",
            "            std=[\n",
            "                58.395,\n",
            "                57.12,\n",
            "                57.375,\n",
            "            ],\n",
            "            to_rgb=True,\n",
            "            type='NormalizeMultiviewImage'),\n",
            "        dict(type='DefaultFormatBundle'),\n",
            "        dict(num_cams=6, type='NuScenesAdaptor', use_ego=False),\n",
            "    ],\n",
            "    type='NuScenesDataset')\n",
            "train_loader = dict(batch_size=1, num_workers=2, shuffle=True)\n",
            "train_pipeline = [\n",
            "    dict(to_float32=True, type='LoadMultiViewImageFromFiles'),\n",
            "    dict(\n",
            "        occ_path='data/surroundocc/samples',\n",
            "        semantic=True,\n",
            "        type='LoadOccupancySurroundOcc',\n",
            "        use_ego=False),\n",
            "    dict(type='ResizeCropFlipImage'),\n",
            "    dict(type='PhotoMetricDistortionMultiViewImage'),\n",
            "    dict(\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        to_rgb=True,\n",
            "        type='NormalizeMultiviewImage'),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(num_cams=6, type='NuScenesAdaptor', use_ego=False),\n",
            "]\n",
            "use_deformable_func = True\n",
            "val_dataset_config = dict(\n",
            "    data_aug_conf=dict(\n",
            "        H=900,\n",
            "        W=1600,\n",
            "        bot_pct_lim=(\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ),\n",
            "        final_dim=(\n",
            "            864,\n",
            "            1600,\n",
            "        ),\n",
            "        rand_flip=True,\n",
            "        resize_lim=(\n",
            "            1.0,\n",
            "            1.0,\n",
            "        ),\n",
            "        rot_lim=(\n",
            "            0.0,\n",
            "            0.0,\n",
            "        )),\n",
            "    data_root='data/nuscenes/',\n",
            "    imageset='data/nuscenes_cam/nuscenes_infos_val_sweeps_occ.pkl',\n",
            "    phase='val',\n",
            "    pipeline=[\n",
            "        dict(to_float32=True, type='LoadMultiViewImageFromFiles'),\n",
            "        dict(\n",
            "            occ_path='data/surroundocc/samples',\n",
            "            semantic=True,\n",
            "            type='LoadOccupancySurroundOcc',\n",
            "            use_ego=False),\n",
            "        dict(type='ResizeCropFlipImage'),\n",
            "        dict(\n",
            "            mean=[\n",
            "                123.675,\n",
            "                116.28,\n",
            "                103.53,\n",
            "            ],\n",
            "            std=[\n",
            "                58.395,\n",
            "                57.12,\n",
            "                57.375,\n",
            "            ],\n",
            "            to_rgb=True,\n",
            "            type='NormalizeMultiviewImage'),\n",
            "        dict(type='DefaultFormatBundle'),\n",
            "        dict(num_cams=6, type='NuScenesAdaptor', use_ego=False),\n",
            "    ],\n",
            "    type='NuScenesDataset')\n",
            "val_loader = dict(batch_size=1, num_workers=2)\n",
            "work_dir = 'out'\n",
            "xyz_coordinate = 'cartesian'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "environmentManger = EnvironmentManager(0, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "lgK9pEDpaukA"
      },
      "outputs": [],
      "source": [
        "modelManager = ModelManager(environmentManger)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "bgKNXgEMa2Mo",
        "outputId": "9e6be4c6-9686-4534-c88c-6864b58c7e1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "03/17 06:36:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Number of trainable parameters: 53,483,255\n",
            "NOT DISTRIBUTED\n",
            "03/17 06:36:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Model initialization complete\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BEVSegmentor(\n",
              "  (img_backbone): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): ResLayer(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "    )\n",
              "    (layer2): ResLayer(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "    )\n",
              "    (layer3): ResLayer(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (6): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (7): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (8): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (9): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (10): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (11): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (12): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (13): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (14): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (15): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (16): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (17): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (18): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (19): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (20): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (21): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (22): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "    )\n",
              "    (layer4): ResLayer(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): ModulatedDeformConv2dPack(\n",
              "          (conv_offset): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
              "    )\n",
              "  )\n",
              "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
              "  (img_neck): FPN(\n",
              "    (lateral_convs): ModuleList(\n",
              "      (0): ConvModule(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (1): ConvModule(\n",
              "        (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (2): ConvModule(\n",
              "        (conv): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (fpn_convs): ModuleList(\n",
              "      (0-2): 3 x ConvModule(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (3): ConvModule(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
              "  (lifter): GaussianLifter()\n",
              "  (encoder): GaussianOccEncoder(\n",
              "    (anchor_encoder): SparseGaussian3DEncoder(\n",
              "      (xyz_fc): Sequential(\n",
              "        (0): Linear(in_features=3, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (4): ReLU(inplace=True)\n",
              "        (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (scale_fc): Sequential(\n",
              "        (0): Linear(in_features=3, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (4): ReLU(inplace=True)\n",
              "        (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (rot_fc): Sequential(\n",
              "        (0): Linear(in_features=4, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (4): ReLU(inplace=True)\n",
              "        (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (opacity_fc): Sequential(\n",
              "        (0): Linear(in_features=1, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (4): ReLU(inplace=True)\n",
              "        (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (semantics_fc): Sequential(\n",
              "        (0): Linear(in_features=17, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (4): ReLU(inplace=True)\n",
              "        (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (output_fc): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (4): ReLU(inplace=True)\n",
              "        (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0): DeformableFeatureAggregation(\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        (kps_generator): SparseGaussian3DKeyPointsGenerator(\n",
              "          (learnable_fc): Linear(in_features=128, out_features=6, bias=True)\n",
              "        )\n",
              "        (output_proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (camera_encoder): Sequential(\n",
              "          (0): Linear(in_features=12, out_features=128, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (4): ReLU(inplace=True)\n",
              "          (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (weights_fc): Linear(in_features=128, out_features=144, bias=True)\n",
              "      )\n",
              "      (1): AsymmetricFFN(\n",
              "        (activate): ReLU(inplace=True)\n",
              "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (layers): Sequential(\n",
              "          (0): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout_layer): Identity()\n",
              "        (identity_fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "      )\n",
              "      (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (3): SparseGaussian3DRefinementModule(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (3): ReLU(inplace=True)\n",
              "          (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (5): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (6): ReLU(inplace=True)\n",
              "          (7): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (8): ReLU(inplace=True)\n",
              "          (9): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (10): Linear(in_features=128, out_features=28, bias=True)\n",
              "          (11): Scale()\n",
              "        )\n",
              "      )\n",
              "      (4): SparseConv3D(\n",
              "        (layer): SubMConv3d(128, 128, kernel_size=[5, 5, 5], stride=[1, 1, 1], padding=[2, 2, 2], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.Native)\n",
              "        (output_proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (6): DeformableFeatureAggregation(\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        (kps_generator): SparseGaussian3DKeyPointsGenerator(\n",
              "          (learnable_fc): Linear(in_features=128, out_features=6, bias=True)\n",
              "        )\n",
              "        (output_proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (camera_encoder): Sequential(\n",
              "          (0): Linear(in_features=12, out_features=128, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (4): ReLU(inplace=True)\n",
              "          (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (weights_fc): Linear(in_features=128, out_features=144, bias=True)\n",
              "      )\n",
              "      (7): AsymmetricFFN(\n",
              "        (activate): ReLU(inplace=True)\n",
              "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (layers): Sequential(\n",
              "          (0): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout_layer): Identity()\n",
              "        (identity_fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "      )\n",
              "      (8): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (9): SparseGaussian3DRefinementModule(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (3): ReLU(inplace=True)\n",
              "          (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (5): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (6): ReLU(inplace=True)\n",
              "          (7): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (8): ReLU(inplace=True)\n",
              "          (9): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (10): Linear(in_features=128, out_features=28, bias=True)\n",
              "          (11): Scale()\n",
              "        )\n",
              "      )\n",
              "      (10): SparseConv3D(\n",
              "        (layer): SubMConv3d(128, 128, kernel_size=[5, 5, 5], stride=[1, 1, 1], padding=[2, 2, 2], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.Native)\n",
              "        (output_proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (11): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (12): DeformableFeatureAggregation(\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        (kps_generator): SparseGaussian3DKeyPointsGenerator(\n",
              "          (learnable_fc): Linear(in_features=128, out_features=6, bias=True)\n",
              "        )\n",
              "        (output_proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (camera_encoder): Sequential(\n",
              "          (0): Linear(in_features=12, out_features=128, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (4): ReLU(inplace=True)\n",
              "          (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (weights_fc): Linear(in_features=128, out_features=144, bias=True)\n",
              "      )\n",
              "      (13): AsymmetricFFN(\n",
              "        (activate): ReLU(inplace=True)\n",
              "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (layers): Sequential(\n",
              "          (0): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout_layer): Identity()\n",
              "        (identity_fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "      )\n",
              "      (14): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (15): SparseGaussian3DRefinementModule(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (3): ReLU(inplace=True)\n",
              "          (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (5): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (6): ReLU(inplace=True)\n",
              "          (7): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (8): ReLU(inplace=True)\n",
              "          (9): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (10): Linear(in_features=128, out_features=28, bias=True)\n",
              "          (11): Scale()\n",
              "        )\n",
              "      )\n",
              "      (16): SparseConv3D(\n",
              "        (layer): SubMConv3d(128, 128, kernel_size=[5, 5, 5], stride=[1, 1, 1], padding=[2, 2, 2], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.Native)\n",
              "        (output_proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (17): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (18): DeformableFeatureAggregation(\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        (kps_generator): SparseGaussian3DKeyPointsGenerator(\n",
              "          (learnable_fc): Linear(in_features=128, out_features=6, bias=True)\n",
              "        )\n",
              "        (output_proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (camera_encoder): Sequential(\n",
              "          (0): Linear(in_features=12, out_features=128, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (4): ReLU(inplace=True)\n",
              "          (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (weights_fc): Linear(in_features=128, out_features=144, bias=True)\n",
              "      )\n",
              "      (19): AsymmetricFFN(\n",
              "        (activate): ReLU(inplace=True)\n",
              "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (layers): Sequential(\n",
              "          (0): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout_layer): Identity()\n",
              "        (identity_fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "      )\n",
              "      (20): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (21): SparseGaussian3DRefinementModule(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (3): ReLU(inplace=True)\n",
              "          (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (5): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (6): ReLU(inplace=True)\n",
              "          (7): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (8): ReLU(inplace=True)\n",
              "          (9): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (10): Linear(in_features=128, out_features=28, bias=True)\n",
              "          (11): Scale()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head): GaussianHead(\n",
              "    (aggregator): LocalAggregator()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelManager.initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KEOGO3ZqNYS"
      },
      "outputs": [],
      "source": [
        "def main(local_rank, args):\n",
        "    \"\"\"\n",
        "    Main entry point for model evaluation.\n",
        "\n",
        "    Args:\n",
        "        local_rank (int): Local rank for distributed processing\n",
        "        args (argparse.Namespace): Command line arguments\n",
        "    \"\"\"\n",
        "    # Initialize environment, model, and dataset managers\n",
        "    env_manager = EnvironmentManager(local_rank, args)\n",
        "    model_manager = ModelManager(env_manager)\n",
        "    dataset_manager = DatasetManager(env_manager)\n",
        "\n",
        "    # Initialize components\n",
        "    model_manager.initialize()\n",
        "    dataset_manager.load_datasets(val_only=True)\n",
        "\n",
        "    # Evaluate the model\n",
        "    evaluator = Evaluator(env_manager, model_manager, dataset_manager)\n",
        "    results = evaluator.evaluate()\n",
        "\n",
        "    # Log final results\n",
        "    env_manager.get_logger().info(f\"Evaluation complete. Final results: {results}\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ujMXTP4JdUt9"
      },
      "outputs": [],
      "source": [
        "from model.segmentor import *\n",
        "from model.backbone import *\n",
        "from model.neck import *\n",
        "\n",
        "#\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "neZoZZ2cd4Hx"
      },
      "outputs": [],
      "source": [
        "from model.lifter import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "roSOYKhxctA9",
        "outputId": "4f456207-8020-4aba-c136-1e245925aefe"
      },
      "outputs": [],
      "source": [
        "from model.encoder import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "TCDS5ZCdd69u",
        "outputId": "8de7393c-31df-49f4-f18f-93ff2f6bff64"
      },
      "outputs": [],
      "source": [
        "from model.head import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_PYxN4xeNdq",
        "outputId": "2755e581-e423-4048-ccca-678d1d5c2700"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5FoJQuLd-_F"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "selfocc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
